---
layout: post
title:  "[Project]빅콘테스트 2018"
subtitle: "블레이드 앤 소울 게임 유저 이탈 예측 모형 설계"
date:   2019-06-10 14:50:13 -0400
categories: Projects
background: '/img/posts/01.jpg'
---

# 0. 들어가며
- 이 프로젝트는 빅콘테스트 2018 Analysis 분야 챔피언리그에 참가한 내용입니다.
- 이 프로젝트 주제는 블레이드 앤 소울 게임 유저 이탈 예측입니다.  
- 저희는 **블린이** 팀으로 참가하여 2등에 해당하는 최우수상(한국정보화진흥원장상)을 수상하였습니다.
- 이 프로젝트는 고동영, 김현우, 김혜주, 손진원과 함께 했습니다.
- 서술의 편의상, 반말로 작성되는 점 양해바랍니다.
---

# 1. Intro

빅콘테스트는 매년 여름부터 늦가을까지 진행되는, 우리 나라에서 가장 큰 빅데이터 공모전 중 하나이다. 한국정보화진흥원과 빅데이터 포럼이 공동으로 주최하며, 2018년에는 신한은행, SK telecom, 신한카드, 엔씨소프트가 주관하였다(주관사는 매년 바뀐다). 그 중 우리가 참가한 Analysis 분야 챔피언리그는 엔씨소프트의 주관하에 이루어졌으며, 총 531개 팀이 참가하였다.

Analysis 분야 챔피언리그의 이번 주제는 엔씨소프트의 블레이드 앤 소울 유저 데이터를 이용하여 해당 유저가 얼마만에 이탈할지를 예측하는 것이었다. 우리에게 주어진 데이터는 아래와 같다.

- activity(324MB) : 유저의 인게임 활동 정보 일주일 단위 집계(총 8주)
- payment(3.5MB) : 유저의 주간 결제 정보
- party(2.4G) : 유저간 파티 구성 단위 집계
- guild(4.7MB) : 문파별 문파원 목록 집계
- trade(1.8G) : 유저간 1:1 거래내역 집계

우리 팀원 중 해당 게임을 플레이해본 사람이 없었기 때문에, 도메인 지식을 얻기 위하여 다같이 피시방에 가서 4시간 정도를 플레이해보았다. 또한 기존 유저들의 생각을 얻기 위해 관련 커뮤니티를 조사해보기도 하였다. 후에도 서술하겠지만, 데이터 분석에서 도메인 지식이 정말 중요하다는 것을  다시금 느끼게  되었다. 우리가 사전조사를 통해 얻은 인사이트는 아래와 같다.

- 레이드 등 재밌는 컨텐츠를 즐기기 위해서는 어느 정도 시간투자가 필요하며, 이에 따라 **초기유저에 대한  진입장벽** 이 존재함을 느낄 수 있었다.
- 기존 유저층 내에서는 다양한 길드와 세력, 파티시스템 등 **유저 간의 활발한 상호작용** 이 일어났다.
- 아이템 획득을 위한 **과금 문제** 와 **직업간 밸런스** 의 문제가 지속적으로 지적되는 것을 확인할 수 있었다.

---

# 2. About Data

우리의 데이터는 크게 세 가지의 특징을 갖고 있었다.

#### 2-1. multiclass

![multiclass](/img/post6/00.png)

우리는 유저를 위의 네 개의 label 중 하나로 분류하는 문제를 풀어야했다. 각 label은 데이터의 측정기간인 8주가 종료된 시점부터 유저의 이탈까지 걸린 기간이며, retained label은 잔류 유저라는 것을 의미한다. training set에서는 각 label 별로 동일하게 1만명의 유저가 배분되어 있었다.  이처럼 label이 2개를 초과하는 경우를 multi-class라 부르며, 이는 (당연히)binary class 분류보다 훨씬 어렵다. 또한, 우리의 최종 모델 평가 기준이 f1-score였기 때문에 더더욱 어려웠다.

#### 2-2. time dependent data

| week | 1 | 2| 3| 4 | 5 | 6 | 7 | 8 |
| --- | --- | --- | --- |  --- | --- | --- |  --- | --- |
|플레이 시간 | 50 | 40 | 60 | none |20 | 70 | 100 | 80 |

위의 데이터는 유저의 게임 플레이 시간에 대한 가상의 데이터이다. 우리 데이터는 위와 같이 유저가 측정기간인 8주 중 게임을 플레이한 주차에 대해서, 그 플레이 시간(및 activity 데이터)이 얼마인지를 보여주었다. 따라서, 각 유저별로 최대 8번의 반복 측정 데이터를 가지고 있었고, 역으로 극단적인 경우에는 마지막 한 주에만 데이터가 있는 경우도 있었다.  이처럼 관찰치가 시간에 종속되어 있다는 특성을 데이터 분석 과정에서 항상 반영해주어야 했다.

#### 2-3. 최초 접속 주차의 특징

![firstweek](/img/post6/1.png)

데이터를 분석하는 과정에서 유저별로 측정기간 중 최초로 접속한 것이 언제인지를 분석해보았는데, 위 그림과 같이 1주 또는 8주에 최초로 접속한 유저들이 가장 많은 것으로 나타났다. 이는 우리의 데이터가 가진 특성 때문인데, 이를 다음 파트인 EDA에서 자세히 분석해보았다.

---
# 3. EDA

*EDA는 너무 양이 많기 때문에 최대한 생략하고 중요한 내용만 서술하겠다.*

### 3-1. 데이터 수집 방식으로 인해 발생하는 문제

![firstweek2](img/post6/11.png)

먼저 위에서 보인 유저별 최초 접속주차를 각 class별로 나눠서 그려보았다. 여기서 확인할 수 있듯이, 이탈하지 않은 유저인 retained 유저와 이탈 유저들 간에 확연한 차이가 드러난다. retained 유저는 1주차에 최초로 접속한 사람의 비율이 매우 높은 반면 이탈 유저들은 1주차와 8주차에 최초접속한 사람들의 비율이 높은 것으로 드러난다. 특히 8주차에 최초 접속한 사람이 많은 것으로 나타나는데, 이는 8주의 데이터 측정기간동안 한 주밖에 접속하지 않았다는 것을 의미한다.


![weekly_connect](/img/post6/2.png)

다음은 각 class 별로 해당 주차에 접속했는지 여부를 파악해보았다. 진한 보라색이 retained이며, 색이 옅어지는 순으로 2month, month, week이다. 위에서 확인할 수 있듯 잔류 유저는 8주 내내 꾸준히 접속한 반면, 이탈 유저들은 소수의 꾸준히 접속하는 사람들과 8주에 갑자기 접속한 유저들로 나뉘는 것을 확인할 수 있다. 이는 **데이터의 수집방식에서 비롯되는 문제** 이다.  
해당 데이터는 8주차에 접속한 사람들을 각 class별로 25000명씩 추출하는 방식으로 수집되었다. 따라서 **8주에는 모든 class별로 25000명이 접속을 해야만** 한다. 하지만 현실적으로 잔류유저는 꾸준히 게임에 접속하던 사람들이었을 가능성이 높은 반면, 이탈 유저는 그렇지 않을 가능성이 높기 때문에 7주에서 8주로 넘어가는 시점에 갑자기 접속비율이 늘어난 것처럼 보이게 된 것이다. 따라서 추후에 데이터 분석을 수행할 때 이러한 데이터 구조상의 특징을 항상 염두에 두고 전처리 하였다.
이렇게 확인한 class별 접속 패턴을 보았을 때, **잔류 유저는 꾸준히 게임을 플레이하는 사람들로 이뤄져있으며, 이탈 유저 들은 일부의 꾸준히 접속하는 유저와 긴 주기로 접속하는 유저, 그리고 8주차에 게임을 처음 시작한 유저로 구성되어 있을 것** 이라는 인사이트를 얻게 되었다.


### 3-2. week 이탈 유저의 접속 패턴

![median_playtime](/img/post6/4.png)

이 그림은 각 class의 각 주차별 게임 플레이 시간의 중위값을 시각화한 것이다. 가장 진한 보라색으로 표시된 잔류 유저들은 예상대로 꾸준히 많은 시간을 매주 플레이하고 있다. 특이하게도, 옅은 파란색으로 표현된 week 이탈 유저들의 주별 플레이 시간이 우상향하는 것을 확인할 수 있다.

![nonconnect_after_first](/img/post6/8.png)

또한 이 그림을 통해 유저가 최초로 접속한 이후 게임을 접속하지 않은 주차를 세어보았을 때, week 이탈 유저는 넓은 범위에 값이 퍼져 있는 반면, 나머지 유저는 비슷한 형태를 띄는 것을 확인할 수 있었다.

위와 같은 일련의 결과는 앞서 확인하였듯이 **week유저들의 상당수가 7/8주차에 게임을 처음 플레이하는 초기 유저이거나 긴 주기로 접속하는 유저이기 때문** 으로 보인다. 일반적으로 처음 게임을 플레이할 때는 해당 게임을 앞으로 꾸준히 할 것인지 파악해보기 위하여, 상대적으로 긴 시간을 탐색에 쏟게 된다. 또한 긴 주기를 가지고 오랜만에 게임에 접속하는 경우 역시 비슷한 이유로 게임 플레이시간이 길어지게 된다. 이와 달리 month와 2month 유저들은 꾸준히 플레이시간의 중위값이 낮은 것을 확인할 수 있는데, 이는 상대적으로 초기 탐색 또는 긴 주기로 접속하는 유저의 비율이 week에 비해 적기 때문으로 보인다.

### 3-3. retained(잔류) 유저의 뚜렷한 특징

![guild](/img/post6/7.png)

위 그림은 각 class별 길드 가입 갯수를 시각화한 것이다. 우리는 사전 조사를 통해 사회성이 게임 플레이 과정에서 중요한 비중을 차지한다는 것을 알고 있었기 때문에, 이 부분에 특히 집중하여 살펴보았다. 위에서 확인할 수 있듯이, 이탈 유저와 잔류(retained)유저는 길드 가입 갯수의 분포가 뚜렷하게 다른 것으로 보인다. 이는 기존 질적 조사 결과와 일치하며, 이를 통해 도메인 지식이 데이터 분석 과정에서 정말 중요함을 다시금 느낄 수 있었다.


![count_connect](/img/post6/10.png)

이 그림은 각 class별로 데이터 수집기간인 8주 중 몇 주를 접속하였는지를 세어본 것이다. 잔류 유저들은 데이터 수집기간인 8주 내내 접속을 한 사람들의 비율이 매우 높은 것을 확인할 수 있으며, 이에 따라 잔류 유저는 꾸준히 게임을 하는 기존 유저들이 대다수의 비율이 차지할 것으로 생각되었다. 이와 달리, 이탈 유저들은 꾸준히 게임을 접속한 사람들과 데이터 수집기간 중 게임을 거의 하지 않은 라이트 유저로 크게 나뉘는 것을 확인할 수 있었다.

### 3-4. EDA 결과

이렇게 변수별 EDA를 모두 수행한 결과, **잔류 유저는 이탈 유저와 다른 패턴** 을 보여주는 경우가 많았기 때문에, 분류모형이 쉽게 분류할 수 있을 것이라 생각되었다. 또한 이탈 유저 내에서도 **week 이탈 유저는 나머지 두 종류의 이탈 유저와 약간씩 다른 패턴** 을 보이는 경우가 있었기 때문에, 이것 역시 분류 모형이 잘 학습할 것이라고 생각되었다.
하지만 **month와 2month 이탈 유저의 경우, 대부분의 변수에서 뚜렷하게 구분되는 패턴을 보여주지 않았기** 때문에 모델이 학습하는 데에 어려움이 있을 것이라고 생각되었다. 이는 이탈 시점이라는 연속적인 값을 임의의 클래스로 분절했기 때문에 발생하는 현상으로 보이며, 이를 잘 분류하도록 모델을 학습시키는 것이 성능 향상의 중요한 포인트가 될 것이라는 사실을 예상할 수 있었다.

---
# 4. Feature Engineering

*FE 역시 짧게 정리하고 넘어가겠다.*

발표 당시 Feature Engineering 과정은 주로 어떠한 변수를 생성했는지에 포인트를 두고 설명하였다. Feature Engineering 과정에 사전에 조사한 도메인 지식과 EDA를 통해 알게된 지식들을 반영해주기 위해 노력하였고, 이 부분을 발표에서도 어필하고자 노력하였다. 가장 중점을 두고 만든 변수는 **유저의 사회성에 관한 지표가 될 수 있는 변수** 들이었으며, 길드 활동 정도, 파티 활동 정도, 유저별 친구 수, 친구들의 class 비율 등을 추가해주었다. 이러한 사회성 지표들은 추후에 모델링에서도 유의미한 변수로서 활용되었다. 또한 앞서 보았듯이 이탈 class별로 접속 패턴이 다른 형태를 띄었기 때문에, **유저의 접속 패턴을 보여줄 수 있는 변수** 들을 추가해주었다.

---

# 5. 초기 모델링

초기에 접근한 모델링 방식으로, 크게 딥러닝적 접근과 머신러닝적 접근을 활용하였다. 이 두 모델은 모두 성능상의 문제로 최종 모델로 활용되지 않았으나, 최종 모델에 활용되는 인사이트를 던져주었다.

### 5-1. 딥러닝적 접근

딥러닝적 접근에서는 NLP 문장분류에서 가장 유명한 딥러닝 모델인 CNN for Sentence Classification을 이 데이터에 적용해보았다. NLP 방법을 쓴 이유는 우리의 데이터 백터가 8주 동안 연속적으로 쌓이는 방식이 일정 길이의 문장을 구성하는 단어에 대한 word vector가 쌓이는 방식과 유사하다고 생각되었기 때문이다. 그 구조는 아래와 같다.

![cnn1](/img/post6/cnn1.pdf)
![cnn2](/img/post6/cnn2.pdf)
![cnn3](/img/post6/cnn3.pdf)
![cnn4](/img/post6/cnn4.pdf)


이처럼 다양한 크기를 갖는 kernel을 결합하면 여러 주차 간의 관계가 고려된 분류 모형을 만들 수 있을 것이라 생각되었으나, validation set에 대하여 f1 score가 높지 않았기에 최종적으로 채택되지는 않았다. 이는 우리의 데이터가 가진 변수가 매우 다양하지만, 상당수의 유저가 일부 변수에 해당하는 행동을 측정 기간동안 아예 하지 않아서 의미상 0을 나타내는 값을 가지는 경우가 많았기 때문으로 보인다. 또한 유저가 아예 접속하지 않은 주에 대해서도 의미상 0을 나타내는 값으로 padding 해주었는데, 결과적으로 들어온 데이터 중 상대적으로 의미있는 부분이 적어졌고 신경망이 이를 쉽게 찾지 못했기 때문으로 보인다. 하지만 대회 제출이 종료된 이후에 구조를 변경하여 추가적으로 모델을 돌려보았을 때 f1 score가 우리의 최종 모델에 가깝게 좋아지는 것을 확인 할 수 있었다.

### 5-2. 머신러닝적 접근

앞서 계속 설명하였듯이 우리의 데이터는 각 유저별로 8주동안 반복 측정된 데이터이며, 각 유저별로 접속횟수가 다르기 때문에 데이터의 형태가 상이하다. 이는 기존의 머신러닝 모델이 받아들이는 데이터의 형식과 다르기 때문에, 데이터를 가공하여 기존의 머신러닝 모델을 이용하고자 시도해보았다. 그 과정에서 유저별 각 주차 값의 중위값을 활용하는 모델과, 유저의 각 주차별 데이터를 각각 다른 유저의 데이터로 보고 독립적으로 모델링 한 뒤에 이를 voting 하는 방식의 repeated predict 모델을 개발하였으나, 모두 성능이 좋지 않았다.

### 5-3. 최종 insight

![flatten1](/img/post6/flatten1.pdf)
![flatten2](/img/post6/flatten2.pdf)

이를 포함한 일련의 과정에서 결론적으로 유저의 각 주별 데이터를 가로로 붙이는, **flattening** 을 시행한 데이터가 최종 데이터 형식에 가장 적합하겠다는 결론을 내릴 수 있었다. 이러한 flattening은 각 주별 변수의 관계를 고려하는 데에 적합하지만 time series 데이터의 특성인 time lag이 일부 무시되는 결점을 가지고 있었다. 따라서 우리는 이 문제를 보완 하기 위해 rolling function을 활용하여 lag variable을 추가하였다. 이는 각 변수의 특정 기간동안의 관련성을 요약하는 정보를 추가해주는 것이다. 이 방식은 flattening 이후에도 데이터의 시계열적인 특성을 반영시켜줄 수 있게 해주었다.
